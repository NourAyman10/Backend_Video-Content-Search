{"metadata":{"colab":{"provenance":[],"gpuType":"T4","collapsed_sections":["oBM3Fu-X-DFa","UKsz128zhSK3","ALyE5ThpiiNQ"]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceType":"datasetVersion","sourceId":8169759,"datasetId":4831063,"databundleVersionId":8292044}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Installations**","metadata":{"id":"oBM3Fu-X-DFa"}},{"cell_type":"code","source":"# !rm -rf /kaggle/working/*\n\n# fast whisper\n!pip install git+https://github.com/SYSTRAN/faster-whisper.git -q -U","metadata":{"execution":{"iopub.status.busy":"2024-04-21T04:28:18.902724Z","iopub.execute_input":"2024-04-21T04:28:18.903404Z","iopub.status.idle":"2024-04-21T04:28:39.210073Z","shell.execute_reply.started":"2024-04-21T04:28:18.903369Z","shell.execute_reply":"2024-04-21T04:28:39.208939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load faster-whisper model\nfrom faster_whisper import WhisperModel\nmodel_size = \"base\"\nmodel = WhisperModel(model_size, device=\"cuda\", compute_type=\"float32\")","metadata":{"id":"n2h5IQ3v-GfR","execution":{"iopub.status.busy":"2024-04-21T04:28:39.212046Z","iopub.execute_input":"2024-04-21T04:28:39.212355Z","iopub.status.idle":"2024-04-21T04:28:46.423232Z","shell.execute_reply.started":"2024-04-21T04:28:39.212312Z","shell.execute_reply":"2024-04-21T04:28:46.422202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# library 4 downloading video & audio from youtube\n!pip install yt-dlp -q -U","metadata":{"id":"HYZe5yT5-Lw6","outputId":"ccee05fd-6645-4054-86bc-8fcd747af46b","execution":{"iopub.status.busy":"2024-04-21T04:28:46.424614Z","iopub.execute_input":"2024-04-21T04:28:46.42544Z","iopub.status.idle":"2024-04-21T04:29:01.75542Z","shell.execute_reply.started":"2024-04-21T04:28:46.425404Z","shell.execute_reply":"2024-04-21T04:29:01.754217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Imports**","metadata":{"id":"UKsz128zhSK3"}},{"cell_type":"code","source":"import subprocess\nimport re\nimport json\nimport time","metadata":{"id":"OPIrs7iyhWa4","execution":{"iopub.status.busy":"2024-04-21T04:29:01.758068Z","iopub.execute_input":"2024-04-21T04:29:01.758389Z","iopub.status.idle":"2024-04-21T04:29:01.76303Z","shell.execute_reply.started":"2024-04-21T04:29:01.758354Z","shell.execute_reply":"2024-04-21T04:29:01.762033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Functions**","metadata":{"id":"ALyE5ThpiiNQ"}},{"cell_type":"code","source":"def download_audio(video_link):\n  # Construct the command with the video link\n  command = fr\"yt-dlp {video_link} --format m4a -o '/kaggle/working/%(id)s.%(ext)s'\"\n\n  # Execute the command to download the audio\n  subprocess.run(command, shell=True)\n\n\ndef download_video(video_link):\n    # Construct the command with the video link and specify the output format as mp4\n    command = fr\"yt-dlp {video_link} -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo+bestaudio' -o '/kaggle/working/%(id)s.%(ext)s'\"\n\n    # Execute the command to download the video\n    subprocess.run(command, shell=True)\n\n\ndef get_video_id(video_link):\n  # Define a regex pattern to match the 'v' parameter in the URL\n  pattern = r'(?:v=|\\/)([a-zA-Z0-9_-]{11})'\n\n  # Search for the pattern in the link\n  match = re.search(pattern, video_link)\n\n  # If match found, return the value of 'v' parameter\n  if match:\n      video_id = match.group(1)\n      return video_id\n  else:\n      return None\n\n\ndef faster_whisper(audio_name):\n  # transcripe audio to segments using faster whisper\n  segments, info = model.transcribe(audio_name, beam_size=5)\n  print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n  return segments\n\n\ndef save_transcription(segments, transcription_file):\n  data_for_json = []\n  for segment in segments:\n      start_hours, start_remainder = divmod(segment.start, 3600)\n      start_minutes, start_seconds = divmod(start_remainder, 60)\n      end_hours, end_remainder = divmod(segment.end, 3600)\n      end_minutes, end_seconds = divmod(end_remainder, 60)\n\n      segment_data = {\n          \"start_time\": \"%02d:%02d:%06.3f\" % (start_hours, start_minutes, start_seconds),\n          \"end_time\": \"%02d:%02d:%06.3f\" % (end_hours, end_minutes, end_seconds),\n          \"text\": segment.text\n      }\n      data_for_json.append(segment_data)\n\n  with open(transcription_file, \"w\", encoding='utf-8') as json_file:\n    json.dump(data_for_json, json_file, indent=4)\n\n\ndef read_transcription(transcription_file):\n  # Reading the data from the JSON filetranscription_entries\n  with open(transcription_file, \"r\", encoding='utf-8') as json_file:\n    transcription_entries = json.load(json_file)\n\n  return transcription_entries\n\n\ndef build_dictionaries(transcription_entries):\n  # Assuming segments_from_json is already defined and loaded as before\n  sentence_dict = {}\n  inverted_index = {}\n\n  start_time = time.time()\n\n  for entry in transcription_entries:\n      sentence = entry['text']\n      timestamps = (entry['start_time'], entry['end_time'])\n      sentence_dict[sentence] = timestamps\n\n      # Normalize by lowercasing and removing punctuation\n      words = set(re.sub(r'\\W+', ' ', sentence.lower()).split())\n      for word in words:\n          if word not in inverted_index:\n              inverted_index[word] = []\n          inverted_index[word].append(sentence)\n\n  end_time = time.time()\n\n  building_time = (end_time - start_time) * 1000\n  return sentence_dict, inverted_index, building_time\n\n\ndef search_by_subset(query, inverted_index, sentence_dict):\n    query_words = set(re.sub(r'\\W+', ' ', query.lower()).split())  # Normalize query\n    sentences_with_query = None\n\n    for word in query_words:\n        if word in inverted_index:\n            if sentences_with_query is None:\n                sentences_with_query = set(inverted_index[word])\n            else:\n                sentences_with_query.intersection_update(inverted_index[word])\n        else:\n            return []  # Early return if any word is not found\n\n    if sentences_with_query is None:\n        return []\n\n    # Return the start timestamps for each matching sentence\n    return sorted(set(sentence_dict[sentence][0] for sentence in sentences_with_query))","metadata":{"id":"Hoy_6o6biosu","execution":{"iopub.status.busy":"2024-04-21T04:29:01.764484Z","iopub.execute_input":"2024-04-21T04:29:01.764972Z","iopub.status.idle":"2024-04-21T04:29:01.786373Z","shell.execute_reply.started":"2024-04-21T04:29:01.764941Z","shell.execute_reply":"2024-04-21T04:29:01.785477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ASR(video_link):\n  # audio preparation\n  download_audio(video_link)\n  video_id = get_video_id(video_link)\n\n  # identify files name\n  audio_name = f\"{video_id}.m4a\"\n  print(\"audio saved to: \", audio_name, \" file\")\n  transcription_file_name = r\"{}.json\".format(video_id)\n\n  # run faster-whisper\n  segments = faster_whisper(audio_name)\n\n  # save transcription to JSON file\n  save_transcription(segments, transcription_file_name)\n\n  # read transcription from json file\n  transcription_entries = read_transcription(transcription_file_name)\n\n  # build dictionaries\n  sentence_dict, inverted_index, building_time = build_dictionaries(transcription_entries)\n  print(\"Building Dictionaries Time:\", building_time , \"milliseconds\")\n\n  return transcription_entries, sentence_dict, inverted_index","metadata":{"id":"J8bZpgvnjRFQ","execution":{"iopub.status.busy":"2024-04-21T04:29:01.787703Z","iopub.execute_input":"2024-04-21T04:29:01.788045Z","iopub.status.idle":"2024-04-21T04:29:01.799974Z","shell.execute_reply.started":"2024-04-21T04:29:01.788015Z","shell.execute_reply":"2024-04-21T04:29:01.799196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\n\n# called 4 each query\ndef search(query, sentence_dict, inverted_index):\n  start_time = time.time()\n\n  start_timestamps = search_by_subset(query, inverted_index, sentence_dict)\n\n  end_time = time.time()\n\n  print(\"Start timestamps for query:\", start_timestamps)\n  print(\"Hashing Searching Time:\", (end_time - start_time) * 1000, \"milliseconds\")\n\n  api = {\"timestamps\": start_timestamps}\n  json_object = json.dumps(api, indent=4)\n  with open(\"/kaggle/working/start_timestamps.json\", \"w\") as outfile:\n      outfile.write(json_object)\n\n  return start_timestamps","metadata":{"id":"sYpznCxKk1HP","execution":{"iopub.status.busy":"2024-04-21T04:31:04.03223Z","iopub.execute_input":"2024-04-21T04:31:04.033078Z","iopub.status.idle":"2024-04-21T04:31:04.039073Z","shell.execute_reply.started":"2024-04-21T04:31:04.033045Z","shell.execute_reply":"2024-04-21T04:31:04.038178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Testing**","metadata":{"id":"3trt1i9tpU9e"}},{"cell_type":"code","source":"import json\nf = open('/kaggle/input/youtube-links/video_link.json')\ndata = json.load(f)\nvideo_link = data['link']\nquery = data['query']\nf.close()\ntranscription_entries, sentence_dict, inverted_index = ASR(video_link)","metadata":{"id":"3l0Hwx4UpUQY","outputId":"3cfe0dac-7162-4094-d5ec-fbe3e1bee035","execution":{"iopub.status.busy":"2024-04-21T04:31:04.042779Z","iopub.execute_input":"2024-04-21T04:31:04.043105Z","iopub.status.idle":"2024-04-21T04:31:08.847739Z","shell.execute_reply.started":"2024-04-21T04:31:04.043081Z","shell.execute_reply":"2024-04-21T04:31:08.846818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Displaying the content\nfor segment in transcription_entries:\n    print(f\"Start Time: {segment['start_time']}, End Time: {segment['end_time']}, Text: {segment['text']}\")","metadata":{"id":"jLtUH8cGp5-3","outputId":"051b6a9e-3289-4a8b-e868-1b73aa2bae1f","execution":{"iopub.status.busy":"2024-04-21T04:31:08.849701Z","iopub.execute_input":"2024-04-21T04:31:08.850366Z","iopub.status.idle":"2024-04-21T04:31:08.85543Z","shell.execute_reply.started":"2024-04-21T04:31:08.850313Z","shell.execute_reply":"2024-04-21T04:31:08.854514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"start_timestamps = search(query, sentence_dict, inverted_index)","metadata":{"id":"05rkNk1Pw1Zf","outputId":"a9ac7923-772c-49d4-c3ca-cc426aa4020a","execution":{"iopub.status.busy":"2024-04-21T04:31:08.856662Z","iopub.execute_input":"2024-04-21T04:31:08.857171Z","iopub.status.idle":"2024-04-21T04:31:08.870458Z","shell.execute_reply.started":"2024-04-21T04:31:08.85714Z","shell.execute_reply":"2024-04-21T04:31:08.869557Z"},"trusted":true},"execution_count":null,"outputs":[]}]}